import os
import json
import cv2
import numpy as np
import time
from collections import defaultdict
from ultralytics import YOLO

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO("yolo11l.pt")

# ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
video_path = "https://strm3.spatic.go.kr/live/312.stream/playlist.m3u8"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    raise Exception("Error: Could not open video.")

# ì„  ì¢Œí‘œ ìˆ˜ì§‘ ë° ë¡œë“œ
def load_or_collect_points(frame):
    coordinates_file = "points.json"
    if os.path.exists(coordinates_file):
        with open(coordinates_file, "r") as f:
            return json.load(f)
    else:
        points = []
        def click_event(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                points.append((x, y))
                cv2.circle(param, (x, y), 5, (0, 255, 0), -1)
                cv2.imshow('Point Collection', param)

        cv2.imshow('Point Collection', frame)
        cv2.setMouseCallback('Point Collection', click_event, frame.copy())

        while len(points) < 4:
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cv2.destroyWindow('Point Collection')
        with open(coordinates_file, "w") as f:
            json.dump(points, f)
        return points

# ì†ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_speed(time_taken, dist=25):
    return round((dist / time_taken) * 3.6, 1) if time_taken > 0 else 0

# ì²« í”„ë ˆì„ì„ ì‚¬ìš©í•˜ì—¬ ì¢Œí‘œ ìˆ˜ì§‘
success, first_frame = cap.read()
if not success:
    raise Exception("Failed to read video")

points = load_or_collect_points(first_frame)
p1, p2, p3, p4 = points

# íŠ¸ë™ íˆìŠ¤í† ë¦¬ ë° ì‹œê°„ ì €ì¥
track_history = defaultdict(list)
vehicle_times = defaultdict(lambda: {'start': None, 'end': None})
vehicle_speeds = {}

# ë¹„ë””ì˜¤ ì²˜ë¦¬
cv2.namedWindow('tracking', flags=cv2.WINDOW_AUTOSIZE)

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break

    # ë‘ í‰í–‰ì„  ê·¸ë¦¬ê¸°
    cv2.line(frame, tuple(map(int, p1)), tuple(map(int, p2)), (0, 255, 0), 2)
    cv2.line(frame, tuple(map(int, p3)), tuple(map(int, p4)), (0, 255, 0), 2)

    # YOLO íŠ¸ë˜í‚¹ ìˆ˜í–‰
    results = model.track(frame, persist=True)

    # ê²€ì¶œëœ ì°¨ëŸ‰ ê°ì²´ ì²˜ë¦¬
    for box, cls, track_id in zip(results[0].boxes.xywh.cpu(), results[0].boxes.cls.cpu().tolist(), results[0].boxes.id.int().cpu().tolist()):
        if cls not in [2, 3, 5, 7]:  # ì°¨ëŸ‰ í´ë˜ìŠ¤ í•„í„°ë§
            continue

        x, y, w, h = box
        x1, y1, x2, y2 = int(x - w / 2), int(y - h / 2), int(x + w / 2), int(y + h / 2)

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

        # ì°¨ëŸ‰ì˜ íŠ¸ë™ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        track = track_history[track_id]
        track.append((float(x), float(y)))
        if len(track) > 30:
            track.pop(0)

        # íŠ¸ë˜í‚¹ ë¼ì¸ ê·¸ë¦¬ê¸°
        if len(track) > 1:
            points = np.array(track, np.int32).reshape((-1, 1, 2))
            cv2.polylines(frame, [points], False, (230, 230, 230), 2)

        # ì°¨ëŸ‰ì´ ì„ ì„ ì§€ë‚˜ëŠ”ì§€ í™•ì¸ ë° ì‹œê°„ ê¸°ë¡
        y_pos = float(y)
        y_line1, y_line2 = (p1[1] + p2[1]) / 2, (p3[1] + p4[1]) / 2

        if track_id not in vehicle_speeds:
            if abs(y_pos - y_line1) < 5 and vehicle_times[track_id]['start'] is None:
                vehicle_times[track_id]['start'] = time.time()
            elif abs(y_pos - y_line2) < 5 and vehicle_times[track_id]['start'] is not None:
                vehicle_times[track_id]['end'] = time.time()
                time_taken = vehicle_times[track_id]['end'] - vehicle_times[track_id]['start']
                vehicle_speeds[track_id] = calculate_speed(time_taken)

        # ì†ë„ í‘œì‹œ
        if track_id in vehicle_speeds:
            cv2.putText(frame, f"ID: {track_id}, Speed: {vehicle_speeds[track_id]} km/h", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # í”„ë ˆì„ ì¶œë ¥
    cv2.imshow("tracking", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
# ì¶œì²˜: https://42morrow.tistory.com/entry/êµí†µ-CCTV-ì˜ìƒ-ê¸°ë°˜ì˜-ìë™ì°¨-ì†ë„-ì¸¡ì • [AI íƒêµ¬ë…¸íŠ¸:í‹°ìŠ¤í† ë¦¬]


# from collections import defaultdict

# import cv2
# import numpy as np

# from ultralytics import YOLO

# model = YOLO("yolo11l.pt")
# video_path = "https://strm3.spatic.go.kr/live/312.stream/playlist.m3u8"
# cap = cv2.VideoCapture(video_path)
# track_history = defaultdict(lambda: [])

# while cap.isOpened():
#     success, frame = cap.read()
#     if success:
#         results = model.track(frame, persist=True)
#         boxes = results[0].boxes.xywh.cpu()
#         track_ids = results[0].boxes.id.int().cpu().tolist()
#         annotated_frame = results[0].plot()
#         for box, track_id in zip(boxes, track_ids):
#             x, y, w, h = box
#             track = track_history[track_id]
#             track.append((float(x), float(y)))
#             if len(track) > 30:
#                 track.pop(0)
#             points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
#             cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)
#         cv2.imshow("YOLO11 Tracking", annotated_frame)
#         if cv2.waitKey(1) & 0xFF == ord("q"):
#             break
#     else:
#         break
# cap.release()
# cv2.destroyAllWindows()

# import cv2
# import numpy as np
# from collections import defaultdict
# from ultralytics import YOLO
# from ultralytics.solutions import SpeedEstimator 

# # --- 1. í™˜ê²½ ë° ë¹„ë””ì˜¤ ì„¤ì • ---
# input_video_path = "https://strm3.spatic.go.kr/live/312.stream/playlist.m3u8" 
# output_video_path = "yolo_tracking_speed_result.mp4"

# cap = cv2.VideoCapture(input_video_path)
# if not cap.isOpened():
#     print("Error: Could not open video stream.")
#     exit()

# # ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
# w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
# h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# fps = cap.get(cv2.CAP_PROP_FPS)

# # ë¹„ë””ì˜¤ ê¸°ë¡ê¸° (VideoWriter) ì´ˆê¸°í™”
# video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
# print(f"ì…ë ¥ ë¹„ë””ì˜¤ W:{w}, H:{h}, FPS:{fps} / ì†ë„ ì¸¡ì • ë° ê²½ë¡œ ì¶”ì  ì‹œì‘...")

# # --- 2. YOLO ë° SpeedEstimator ì´ˆê¸°í™” ---
# # COCO ë°ì´í„°ì…‹ ì°¨ëŸ‰ ê´€ë ¨ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (car, motorcycle, bus, truck)
# vehicle_classes = [2, 3, 5, 7] 

# # ì†ë„ ì¸¡ì • ì˜ì—­(line_pts) ì„¤ì •: ì¤‘ì•™ ì„¸ë¡œì„  ì˜ˆì‹œ
# line_pts = [(360,1280), (360,320)] 

# # SpeedEstimator ê°ì²´ ìƒì„± 
# speed_obj = SpeedEstimator(
#     model="yolo11l.pt",
#     fps=fps,
#     classes=vehicle_classes,
#     region=line_pts,
#     meter_per_pixel=0.005, # í”½ì…€ ë‹¹ ë¯¸í„° ê°’ (í™˜ê²½ì— ë§ê²Œ ì¡°ì • í•„ìš”)
#     max_speed=120,
#     show=False,
#     max_hist=3,
#     conf=0.5,
#     iou=0.5,
#     tracker="bytetrack.yaml"
# ) 

# # --- 3. ì¶”ì  ê²½ë¡œ ì €ì¥ì„ ìœ„í•œ defaultdict ì´ˆê¸°í™” ---
# track_history = defaultdict(lambda: [])

# # --- 4. ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„ ---
# while cap.isOpened():
#     success, frame = cap.read()
#     if not success: 
#         print("End of video stream or failed to read frame.")
#         break
    
#     # 4.1. â­ï¸ ì†ë„ ê³„ì‚° ë° ì‹œê°í™” (SpeedEstimator í˜¸ì¶œ)
#     results = speed_obj(frame) 
#     annotated_frame = results.plot_im # SpeedEstimatorê°€ ê·¸ë¦° í”„ë ˆì„ (ì†ë„, ê²½ê³„ ìƒì í¬í•¨)
    
#     # 4.2. â­ï¸ ì¶”ì  ê²½ë¡œ ê·¸ë¦¬ê¸° ë¡œì§ í†µí•© (ì—ëŸ¬ ë°œìƒ ë¶€ë¶„ ìˆ˜ì •)
    
#     # ğŸš¨ ìˆ˜ì •ëœ ë¡œì§: 'boxes' ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆë‹¤ë©´ IDê°€ ìˆëŠ”ì§€ ì¶”ê°€ í™•ì¸
#     if hasattr(results, 'boxes') and results.boxes.id is not None:
#         boxes = results.boxes.xywh.cuda() # x, y, w, h
#         track_ids = results.boxes.id.int().cuda().tolist() # ì¶”ì  ID
        
#         for box, track_id in zip(boxes, track_ids):
#             x, y, w_box, h_box = box # ë°•ìŠ¤ ì •ë³´
            
#             # ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ê²½ë¡œì— ì¶”ê°€
#             center_x, center_y = float(x), float(y)
#             track = track_history[track_id]
#             track.append((center_x, center_y))
            
#             # ê²½ë¡œ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 30 í”„ë ˆì„)
#             if len(track) > 30:
#                 track.pop(0)
            
#             # ê²½ë¡œë¥¼ cv2.polylines() í˜•ì‹ì— ë§ê²Œ ë³€í™˜
#             points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))
            
#             # ì¶”ì  ê²½ë¡œë¥¼ í˜„ì¬ í”„ë ˆì„(annotated_frame)ì— ê·¸ë¦¬ê¸°
#             cv2.polylines(
#                 annotated_frame, 
#                 [points], 
#                 isClosed=False, 
#                 color=(0, 255, 255), # ì²­ë¡ìƒ‰
#                 thickness=4 
#             )

#     # 4.3. ì‹œê°í™” ë° ì¢…ë£Œ ì¡°ê±´
#     cv2.imshow("YOLO Tracking and Speed Estimation", annotated_frame)
    
#     # ì¶œë ¥ ë¹„ë””ì˜¤ì— í”„ë ˆì„ ì“°ê¸°
#     video_writer.write(annotated_frame)
    
#     if cv2.waitKey(1) & 0xFF == ord("q"):
#         break

# # --- 5. ì¢…ë£Œ ë° ë¦¬ì†ŒìŠ¤ í•´ì œ ---
# cap.release()
# video_writer.release()
# cv2.destroyAllWindows()
# print(f"ì²˜ë¦¬ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: {output_video_path}")