# import cv2
# from ultralytics import YOLO
# from ultralytics.solutions import SpeedEstimator 
# # YOLO ëª¨ë¸ì€ SpeedEstimator ê°ì²´ì— ì¸ìˆ˜ë¡œ ì „ë‹¬ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œ ë¡œë“œí•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.
# # model = YOLO("yolov11n.pt") 

# # 2. ì…/ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì • 
# input_video_path = "https://strm3.spatic.go.kr/live/312.stream/playlist.m3u8" 
# output_video_path = "speed_test_result.mp4"
# cap = cv2.VideoCapture(input_video_path)
# if not cap.isOpened(): exit()
# w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
# h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# fps = cap.get(cv2.CAP_PROP_FPS)
# video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
# print(f"ì…ë ¥ ë¹„ë””ì˜¤ W:{w}, H:{h}, FPS:{fps} / ì†ë„ ì¸¡ì • ì‹œì‘...")


# # 4. â­ï¸ ì†ë„ ì¸¡ì •ê¸° (SpeedEstimator) ì´ˆê¸°í™” (ëª¨ë“  ì„¤ì •ì„ ì—¬ê¸°ì— ì§‘ì¤‘)
# # -----------------------------------------------------------------------------------------
# # COCO ë°ì´í„°ì…‹ ì°¨ëŸ‰ ê´€ë ¨ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
# vehicle_classes = [2, 3, 5, 7] 

# # ğŸš¨ line_pts (region) ì„¤ì •ì€ SpeedEstimatorì˜ ë‚´ë¶€ ì¶”ì  ì˜ì—­ì„ ì„¤ì •í•©ë‹ˆë‹¤.
# # ì´ ê°’ì€ ì´ˆê¸°í™” ì‹œì ì— ì¸ìˆ˜ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
# # ì¤‘ì•™ ë¼ì¸: (w // 2, h)ì™€ (w // 2, h // 4) 
# line_pts = [(360,1280), (360,320)] 

# # SpeedEstimator ê°ì²´ ìƒì„± ì‹œ ëª¨ë“  ì¸ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
# # SpeedEstimatorê°€ model.track() ê¸°ëŠ¥ì„ ë‚´ë¶€ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
# speed_obj = SpeedEstimator(
#     model="yolo11l.pt",
#     fps=fps,
#     classes=vehicle_classes,
#     region=line_pts,
#     meter_per_pixel=0.00006,
#     max_speed = 120,
#     show=True,
#     max_hist = 3,
#     conf= 0.3,
#     iou = 0.5,
#     tracker = "bytetrack.yaml"
# ) 
# # -----------------------------------------------------------------------------------------


# # 5. ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„
# while cap.isOpened():
#     success, frame = cap.read()
#     if not success: break
    
#     # 6. â­ï¸ ì†ë„ ê³„ì‚° ë° ì‹œê°í™” (ìµœì¢… API í˜¸ì¶œ)
#     # ğŸš¨ SpeedEstimator ê°ì²´ ìì²´ë¥¼ ì›ë³¸ í”„ë ˆì„ë§Œ ê°€ì§€ê³  í˜¸ì¶œí•©ë‹ˆë‹¤.
#     #    ê°ì²´ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì¶”ì (Tracking)ê³¼ ì†ë„ ê³„ì‚°ì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
#     results = speed_obj(frame) 
    
#     # 7. ì‹œê°í™” (ê²°ê³¼ì˜ plot_im ì†ì„± ì‚¬ìš©)
#     # SpeedEstimatorëŠ” SolutionResults ê°ì²´ë¥¼ ë°˜í™˜í•˜ë©°, ì´ë¯¸ì§€ ë°ì´í„°ëŠ” plot_imì— ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.
#     annotated_frame = results.plot_im
    
#     # 8. ì¶œë ¥ ë¹„ë””ì˜¤ì— í”„ë ˆì„ ì“°ê¸°
#     video_writer.write(annotated_frame)

# # 9. ì¢…ë£Œ ë° ë¦¬ì†ŒìŠ¤ í•´ì œ
# cap.release()
# video_writer.release()
# cv2.destroyAllWindows()
# print(f"ì²˜ë¦¬ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: {output_video_path}")

import cv2
import numpy as np

# 1. ì‚¬ìš©í•  CCTV ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_path = 'https://stream6.bcits.go.kr/bucheon/TM090TC08P.stream/playlist.m3u8' 
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

# ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ì½ì–´ì™€ì„œ í”½ì…€ ì„ íƒì— ì‚¬ìš©
success, frame = cap.read()
if not success:
    print("Error: Failed to read the first frame.")
    exit()

# 2. ì „ì—­ ë³€ìˆ˜ ì„¤ì •
selected_points = []
window_name = "Select 4 Source Points (src_pts)"

# 3. ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ í•¨ìˆ˜
def get_points(event, x, y, flags, param):
    """ë§ˆìš°ìŠ¤ í´ë¦­ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  í”½ì…€ ì¢Œí‘œë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    if event == cv2.EVENT_LBUTTONDOWN:
        if len(selected_points) < 4:
            # í´ë¦­ëœ í”½ì…€ ì¢Œí‘œ ì €ì¥
            selected_points.append((x, y))
            
            # ì‹œê°ì  í”¼ë“œë°±: í´ë¦­í•œ ìœ„ì¹˜ì— ì‘ì€ ì› ê·¸ë¦¬ê¸°
            cv2.circle(frame_copy, (x, y), 5, (0, 255, 0), -1)
            
            # í˜„ì¬ê¹Œì§€ ì„ íƒëœ ì ì˜ ê°œìˆ˜ í‘œì‹œ
            text = f"Point {len(selected_points)}: ({x}, {y})"
            cv2.putText(frame_copy, text, (x + 10, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            print(f"Selected Point {len(selected_points)}: ({x}, {y})")
            
            # 4ê°œì˜ ì ì´ ëª¨ë‘ ì„ íƒë˜ë©´ ë‹¤ê°í˜•ì„ ê·¸ë ¤ ì‹œê°í™”
            if len(selected_points) == 4:
                # 4ê°œì˜ ì ì„ ì—°ê²°í•˜ì—¬ ì§ì‚¬ê°í˜• ì˜ì—­ í‘œì‹œ (ë…¸ë€ìƒ‰)
                pts = np.array(selected_points, np.int32)
                pts = pts.reshape((-1, 1, 2))
                cv2.polylines(frame_copy, [pts], isClosed=True, color=(0, 255, 255), thickness=2)
                print("\n--- 4ê°œ ì  ì„ íƒ ì™„ë£Œ ---")
                print("Press 'q' to finish and see the final src_pts array.")

# 4. ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì • ë° í”„ë ˆì„ í‘œì‹œ
cv2.namedWindow(window_name)
cv2.setMouseCallback(window_name, get_points)

print("--- 4ê°œì˜ ì†ŒìŠ¤ í¬ì¸íŠ¸(src_pts)ë¥¼ ìˆœì„œëŒ€ë¡œ í´ë¦­í•˜ì„¸ìš” ---")
print("1. ì¢Œìƒë‹¨ (Upper-Left)")
print("2. ìš°ìƒë‹¨ (Upper-Right)")
print("3. ì¢Œí•˜ë‹¨ (Lower-Left)")
print("4. ìš°í•˜ë‹¨ (Lower-Right)")

while True:
    # ì›ë³¸ í”„ë ˆì„ì„ ë³µì‚¬í•˜ì—¬ ë§ˆí¬ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    frame_copy = frame.copy()
    
    # ì„ íƒëœ ì ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°í™” (ì„ íƒì´ ì§„í–‰ ì¤‘ì¼ ë•Œ)
    if 1 < len(selected_points) <= 4:
        for i in range(len(selected_points)):
            cv2.circle(frame_copy, selected_points[i], 5, (0, 255, 0), -1)
        
        # í˜„ì¬ê¹Œì§€ì˜ ì ë“¤ì„ ì—°ê²°
        if len(selected_points) == 4:
            pts = np.array(selected_points, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(frame_copy, [pts], isClosed=True, color=(0, 255, 255), thickness=2)

    cv2.imshow(window_name, frame_copy)
    
    # 'q' í‚¤ë¥¼ ëˆ„ë¥´ê±°ë‚˜ 4ê°œì˜ ì ì´ ëª¨ë‘ ì„ íƒë˜ë©´ ë£¨í”„ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q') or len(selected_points) == 4:
        break

cv2.destroyAllWindows()
cap.release()

# 5. ìµœì¢… src_pts ë°°ì—´ ì¶œë ¥
if len(selected_points) == 4:
    # np.float32 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
    final_src_pts = np.float32(selected_points)
    print("\n--- ìµœì¢… src_pts ë°°ì—´ (ì½”ë“œë¡œ ì‚¬ìš©) ---")
    print(f"src_pts = {final_src_pts}")
else:
    print("4ê°œì˜ ì ì´ ëª¨ë‘ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")